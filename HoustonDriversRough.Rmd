---
title: "Houston Drivers Rough"
author: "Will Curkan"
date: "2023-04-15"
output:
  pdf_document: default
  html_document: default
subtitle: An Analysis of Moving Violations in Houston
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
```

## Introduction 

Southern Texas's "greater Houston area" is a 665 $mi^2$ [cite] section of land surrounded by and surrounding many municipalities [Cite]. The population of the metropolitan and its populous suburbs generate much automobile traffic; travelling to destinations in and around Houston can take hours during the work-school "rush hours". Due to Houston's size and considerable traffic, people feel rushed, break the speed limit laws, and get pulled over. Conveniently, Houston police departments provide their traffic-stop data to the Stanford Policing Project that open-sources the data via their website [Cite].

If you've been stopped for a traffic violation, you know the citation shows the date, time, location, violation type, speed, and posted speed, among other things. The dataset contains 21 column features, but we will only work with the following:

|Feature|Description|
|-------|-----------|
|speed  | Speed of vehicle|
|posted_speed| Posted speed limit|
|vehicle_make| Brand of vehicle|
|date| date citation was issued|

But just looking at those features individually is neither descriptive nor interesting. I create a new feature called `ratio`.

|Feature|Description|
|-------|-----------|
|ratio  | Ratio of vehicle speed to posted limit|

-----------------------------------------------------------------


### Problem

The size of roads and accidents in the most heavily populated areas makes for a energy-draining daily commute that implore breaking the speed limit.

---------------------------------------------------------------------

### Purpose

Whilst difficult to even speculate infrastructure changes to soothe, it is possible that increasing the speed limits may alleviate traffic. Therefore, the purpose of this paper is to use frequentist and Bayesian analysis on the data given about speeding tickets to infer on the population parameters of:

- the ratio of actual speed versus posted speed limit
- the time between traffic stops
- the number of stops per day
- is there a difference among drivers of different car brands?

with the hopes of getting better insight into the traffic problem and hypothesizing solutions.


## Results and Discussion

The data required some cleaning. To get a nice distribution of the speed `ratio`, cleaning out 1,433,649 `NA` values was necessary. Leaving 612,323 points to visualize the distribution. But this is quite a lot of data, so we will only look at the initial distribution and then use a random sample of the data.

```{r LIBRARIES, message = F, warning = F}
library(dplyr, quietly = T)
library(ggplot2)
library(rjags)
library(ggpubr)
source("DBDA2E-utilities.R")
```

```{r DATA}
data <- read.csv('tx_houston_2023_01_26.csv')
```


```{r INITIAL RATIO HIST}
# ratio of raw speed to posted speed limit
raw_posted_ratio <- data$speed / data$posted_speed

# Remove the speed ratios that became NA
# due to an undocumented speed 
# (could be many reasons like it not 
# being a speeding violation, or officer error)
raw_posted_ratio <- raw_posted_ratio[!is.na(raw_posted_ratio)]

# Dont need to input a dataframe: NULL
ggplot(NULL, aes(x=raw_posted_ratio)) +
  geom_histogram(bins = 250) +
  geom_vline(aes(xintercept=mean(raw_posted_ratio)),
            color="blue", linetype="dashed", linewidth=1) +
  labs(title = 'Ratio of Raw Speed vs. Posted Speed Limit', x = 'Ratio')
```

```{r INITIAL RATIO SUMMARY, eval = F}
summary(data$speed[!is.na(data$speed)])
round(summary(raw_posted_ratio),2)
```

--------------------------------------------------------------------

There's a huge problem with this distribution: some values are over double, triple, and even 15 times the speed limit. Let's think of this logically. If someone is travelling even five times the speed limit of 20MPH, they're going 100MPH. That's fine, but a road with a 20MPH limit is likely small, so going 100mph almost seems unreasonable. Further, if someone is caught travelling over 10 times the speed limit at 20 or 30MPH, they'd be going 200 and 300MPH, or someone going 60MPH would be travelling at 600MPH. This isn't realistic. Also, the maximum speed is 753 miles per hour, "that's faster than an airplane" - Dr. Cahoy, circa 2023.

Feature|Min.| 1st Qu.|  Median |   Mean |3rd Qu. |   Max.|
|------|----|--------|---------|--------|--------|-------|
|speed|1.00 |  45.00 |  56.00 |  58.64   |74.00  |753.00|
|ratio|0.03 |   1.24  |  1.32 |   1.34  |  1.43 |  17.33|

We will consider only vehicles meeting two conditions:

- found to be speeding: their logged speed exceeds the posted speed limit
  - `speed` > `posted_speed`
  - This forces `ratio` > 1 and confirms the vehicle was speeding
- `speed` is less than 155MPH: the governed speed [1]
  - `speed` $\leq$ 155
  - It's unreasonable to think a car is travelling on a public road at over this speed.

```{r FILTERED DATASET}
# 155 is the governed speed
# must be speeding; speed > posted_speed
data = data %>%
  filter(speed <= 155, speed > posted_speed)
```

```{r FILTER BY MANUFACTURER}
s <- data %>%
  select('vehicle_make', 'speed', 'posted_speed')
s$ratio<- s$speed / s$posted_speed
s$vehicle_make <- as.factor(s$vehicle_make)

majors <- c('FORD', 'HONDA', 'TOYOTA', 'CHEVY')

# Gets indices of toyota
toyo_idx <- which(regexpr('TOY', s$vehicle_make, ignore.case = T) >= 1)
# Get indices of honda
hond_idx <- which(regexpr('HON', s$vehicle_make, ignore.case = T) >= 1)
# Get indices of Ford
ford_idx <- which(regexpr('FO', s$vehicle_make, ignore.case = T) >= 1)
# Get indices for Chevy
chev_idx <- which(regexpr('CHEV', s$vehicle_make, ignore.case = T) >= 1)
# Need to change every instance found by indices to single category for each index
s[toyo_idx,]$vehicle_make <- 'TOYOTA'
s[hond_idx,]$vehicle_make <- 'HONDA'
s[ford_idx,]$vehicle_make <- 'FORD'
s[chev_idx,]$vehicle_make <- 'CHEVY'

# Filter so we only get cars in the `majors` variable
s2 <- s %>%
  filter(vehicle_make %in% majors)

########## NEED BELOW PLOT FOR LATER ##################

# Boxplot of speed ratios by car manufacturer
ggplot(s2[s2$ratio <= 2.5,], aes(x = vehicle_make, y = ratio)) +
  geom_boxplot()
```


### EDA

```{r FILTERED RATIO AND PLOT}
 ############ REDO THE RAW_POSTED_RATIO #############

# ratio of raw speed to posted speed limit
raw_posted_ratio <- data$speed / data$posted_speed


raw_posted_ratio <- raw_posted_ratio[ raw_posted_ratio > 1 & raw_posted_ratio < 2.5]

length(raw_posted_ratio)

# Remove the speed ratios that became NA
# due to an undocumented speed 
# (could be many reasons like it not 
# being a speeding violation, or officer error)
raw_posted_ratio <- raw_posted_ratio[!is.na(raw_posted_ratio)]

# Dont need to input a dataframe: NULL
ggplot(NULL, aes(x=raw_posted_ratio)) +
  geom_histogram(bins = 50) +
  geom_vline(aes(xintercept=mean(raw_posted_ratio)),
            color="blue", linetype="dashed", linewidth=1)

# Want to place the dataset's statistics at the end.
# summary(raw_posted_ratio)
# sd(raw_posted_ratio)
```


```{r SAMPLE}
# Let's just use a sample of 50 - 200 for the project
# because it doesnt make much sense otherwise
set.seed(42)
x <- sample(raw_posted_ratio, 60)

xbar <- mean(x)
s <- sd(x)


hist(x, main = 'Distribution of a Random Sample of Size 60', 
     xlab = 'Ratio')
```

```{r BOOTSTRAP MEAN}
# set.seed(42)
n <- length(x)

N <- 10^5

boot_means <- numeric(N)
boot_sds <- numeric(N)

for (i in 1:N)
{
  boot_sample <- sample(x, n, replace = T)
  boot_means[i] <- mean(boot_sample)
  boot_sds[i] <- sd(boot_sample)
}

# hist(boot_means)


######################### SKEWED ##############
# qqnorm(boot_means)
# qqline(boot_means)

# mean(boot_means)
# sd(boot_means)
# 
# mean(boot_sds)
# 
# quantile(boot_means, c(.025,.975))
```

### Prior Assumptions

For simplicity, I assume the ratio of speeds is normally distributed.

$\theta$ is the the true mean ratio of speed to speed limit.

We will consider three priors:

1. A non-informative prior assumption on $\theta$

2. $\theta$ based on the sample statistics

3. $\theta$ based on the bootstrap statistics
  - A bootstrap distribution was simulated in the code.

4. Gamma and conjugate prior


```{r prior distribution on sample/bootstrap statistics}
set.seed(42)
#######################################################################
############# PRIOR DISTRIBUTION ON SAMPLE STATISTICS #################
#######################################################################
rate <- 1000
shape <- round(s * rate)

Nrep <- 10^5
# Sample mean `xbar` and sample sd `s` from SAMPLE block
mu_sim_prior = rnorm(Nrep, xbar, s)
tau_sim_prior = rgamma(Nrep, shape = shape, rate = rate)

p1 <- ggplot(NULL, aes(mu_sim_prior, tau_sim_prior)) +
  geom_point(color = "skyblue", alpha = 0.4) +
  geom_density_2d(color = "orange", linewidth = 1) +
  labs(xlab = 'Ratio', ylab = '', title = 'Sample Mean Prior')

set.seed(42)
#######################################################################
########## PRIOR DISTRIBUTION ON BOOTSTRAPPED STATISTICS ##############
#######################################################################
rate <- 1000
shape <- round(mean(boot_sds) * rate)

mu_sim_prior = rnorm(Nrep, mean(boot_means), mean(boot_sds))
tau_sim_prior =rgamma(Nrep, shape = shape, rate = rate)
# sigma_sim_prior = 1 / sqrt(tau_sim_prior)
# sim_prior = data.frame(mu_sim_prior, tau_sim_prior, sigma_sim_prior)
p2 <- ggplot(NULL, aes(mu_sim_prior, tau_sim_prior)) +
  geom_point(color = "skyblue", alpha = 0.4) +
  geom_density_2d(color = "orange", linewidth = 1) +
  labs(xlab = 'Ratio', ylab = '', title = 'Bootstrap Mean Prior')

ggarrange(p1, p2)
```



```{r JAGs on Sample Stats prior}
set.seed(42)
##############################################################################
################### ASSUMPTIONS BASED ON SAMPLE STATISTICS ###################
##############################################################################

n <- length(x)

model_string <- "model{

  # Likelihood
  for (i in 1:n){
    x[i] ~ dnorm(mu, 1 / sigma ^ 2)
  }
  #sigma <- .05
  

  # Prior
  mu ~ dnorm(mu0, 1 / tau0 ^ 2)
  
  # Sample mean with size 30
  #mu0 <-  1.393571
  
  # Sample mean ith size 60
  mu0 <- 1.340332
  
  tau0 <- 1 / 0.04827723 # Actually the mean's SD
  
  # Sample sd with size 30
  #sigma <- 0.2696776
  
  # Sample sd with size 60
  sigma <- 0.2149536

}"

# Compile the model
dataList = list(x=x, n=n)
model <- jags.model(textConnection(model_string),
                    data=dataList,
                    n.chains=5, quiet = T) 

update(model, 2000, progress.bar="none")

posterior_sample <- coda.samples(model, 
                                 variable.names=c("mu"),# 'sigma'),
                                 n.iter=100000,
                                 progress.bar="none")
# Summarize and check diagnostics
summary(posterior_sample)


## --------------------------------
plot(posterior_sample)

#######################################################
#################### DIAGNOSTICS ######################
#######################################################

# diagMCMC(posterior_sample,saveName = "diagMCMCeg1",
# saveType = "jpg")

#######################################################
########### POSTERIOR PREDICTIVE DISTRIBUTION #########
#######################################################

theta_sim = as.matrix(posterior_sample)
x_sim = rnorm(nrow(theta_sim), theta_sim[, "mu"], 0.2696776)#, theta_sim[, "sigma"])
quantile(x_sim, c(0.025, 0.975))
hist(x_sim, freq = FALSE, xlab = "Ratio of raw speed to posted limit",
     main = "Posterior preditive distribution")
lines(density(x_sim))
abline(v = quantile(x_sim, c(0.025, 0.975)), col = "orange")
```



```{r JAGs on Bootstrapped stats prior}
set.seed(42)
##############################################################################
############## ASSUMPTIONS BASED ON BOOTSTRAPPED STATISTICS ##################
##############################################################################

model_string <- "model{

  # Likelihood
  for (i in 1:n){
    x[i] ~ dt(mu, 1 / sigma ^ 2, tdf0)
  }

  # Prior
  #mu ~ dnorm(mu0, 1 / tau0 ^ 2)
  mu ~ dnorm(mu0, 0.02745854)
  mu0 <- 1.340342 # Mean of the bootstrap means
  #tau0 ~ dgamma(1,100)
  # sigma <- 1 / sqrt(tau0)
  # tau0 <- .259205 # Mean of bootstrap SDs
  sigma <- .2149536 # Mean of bootstrap SDs
  tdf0 <- 59

}"

# Compile the model
dataList = list(x=raw_posted_ratio, n=n)
model <- jags.model(textConnection(model_string),
                    data=dataList,
                    n.chains=5, quiet = T) 

update(model, 2000, progress.bar="none")

posterior_sample <- coda.samples(model, 
                                 variable.names=c("mu", 'sigma', 'tdf0'),
                                 n.iter=N,
                                 progress.bar="none")
# Summarize and check diagnostics
summary(posterior_sample)


## --------------------------------
plot(posterior_sample)

#######################################################
#################### DIAGNOSTICS ######################
#######################################################

# diagMCMC(posterior_sample,saveName = "diagMCMCeg",
# saveType = "jpg")

#######################################################
########### POSTERIOR PREDICTIVE DISTRIBUTION #########
#######################################################

theta_sim = as.matrix(posterior_sample)
x_sim = rnorm(nrow(theta_sim), theta_sim[, "mu"], theta_sim[, "sigma"])
quantile(x_sim, c(0.025, 0.975))
hist(x_sim, freq = FALSE, xlab = "Ratio of raw speed to posted limit",
     main = "Posterior preditive distribution")
lines(density(x_sim))
abline(v = quantile(x_sim, c(0.025, 0.975)), col = "orange")



```

```{r JAGS on Noninformative Prior}
set.seed(42)
##############################################################################
############## ASSUMPTIONS BASED ON NONINFORMATIVE PRIOR  ####################
##############################################################################

model_string <- "model{

  # Likelihood
  for (i in 1:n){
    x[i] ~ dnorm(mu, 1 / sigma ^ 2)
  }

  # Prior
  mu ~ dnorm(1.5, 50)
  sigma <- .21

}"

# Compile the model
dataList = list(x=raw_posted_ratio, n=n)
model <- jags.model(textConnection(model_string),
                    data=dataList,
                    n.chains=5, quiet = T) 

update(model, 2000, progress.bar="none")

posterior_sample <- coda.samples(model, 
                                 variable.names=c("mu"),# 'sigma'),
                                 n.iter=N,
                                 progress.bar="none")
# Summarize and check diagnostics
summary(posterior_sample)


## --------------------------------
plot(posterior_sample)

#######################################################
#################### DIAGNOSTICS ######################
#######################################################

# diagMCMC(posterior_sample,saveName = "diagMCMCeg",
# saveType = "jpg")

#######################################################
########### POSTERIOR PREDICTIVE DISTRIBUTION #########
#######################################################

theta_sim = as.matrix(posterior_sample)
x_sim = rnorm(nrow(theta_sim), theta_sim[, "mu"]) #, theta_sim[, "sigma"])
quantile(x_sim, c(0.025, 0.975))
hist(x_sim, freq = FALSE, xlab = "Ratio of raw speed to posted limit",
     main = "Posterior preditive distribution")
lines(density(x_sim))
abline(v = quantile(x_sim, c(0.025, 0.975)), col = "orange")
```


JAGS ON GAMMA PRIOR

```{r}
set.seed(42)
##############################################################################
############## ASSUMPTIONS BASED ON BOOTSTRAPPED STATISTICS ##################
##############################################################################

model_string <- "model{

  # Likelihood
  for (i in 1:n){
    x[i] ~ dgamma(shape,rate)
    # x[i] ~ dgamma(96,75)
  }

  # Prior
  
  #mu ~ dgamma(96,75)
  mu ~ dgamma(shape, rate)
  shape ~ dnorm(96, 10)
  rate ~ dnorm(75, 10)
  

}"

# Compile the model
dataList = list(x=raw_posted_ratio, n=n)
model <- jags.model(textConnection(model_string),
                    data=dataList,
                    n.chains=5, quiet = T) 

update(model, 2000, progress.bar="none")

posterior_sample <- coda.samples(model, 
                                 variable.names=c("mu", 'shape', 'rate'),
                                 n.iter=N,
                                 progress.bar="none")
# Summarize and check diagnostics
summary(posterior_sample)


## --------------------------------
plot(posterior_sample)

#######################################################
#################### DIAGNOSTICS ######################
#######################################################

# diagMCMC(posterior_sample,saveName = "diagMCMCeg",
# saveType = "jpg")

#######################################################
########### POSTERIOR PREDICTIVE DISTRIBUTION #########
#######################################################

theta_sim = as.matrix(posterior_sample)
x_sim = rgamma(nrow(theta_sim), theta_sim[,'shape'], theta_sim[,'rate'])
quantile(x_sim, c(0.025, 0.975))
hist(x_sim, freq = FALSE, xlab = "Ratio of raw speed to posted limit",
     main = "Posterior preditive distribution")
lines(density(x_sim))
abline(v = quantile(x_sim, c(0.025, 0.975)), col = "orange")
```



dgamma(32, 25)
-0.7294995  3.2886307

dgamma(96, 75)
2.5%      97.5% 
-0.6984269  3.2544228



```{r}
set.seed(42)

p <- prod(x)
q <- sum(x)
##############################################################################
############## ASSUMPTIONS BASED ON A GAMMA PRIOR  ###########################
##############################################################################

model_string <- "model{

  # Likelihood
  for (i in 1:n){
    x[i] ~ dgamma(shape,rate)
    # x[i] ~ dgamma(96,75)
  }

  # Prior
  shape ~ dnorm(96, 1 / 3^2)
  rate ~ dnorm(75, 1 / 3^2)
  
  # Exp prior
  
  
  
}"

# Compile the model
dataList = list(x=raw_posted_ratio, n=n)
model <- jags.model(textConnection(model_string),
                    data=dataList,
                    n.chains=5, quiet = T) 

update(model, 1000, progress.bar="none")

posterior_sample <- coda.samples(model, 
                                 variable.names=c('shape', 'rate'),
                                 n.iter=10000,
                                 progress.bar="none")
# Summarize and check diagnostics
summary(posterior_sample)


## --------------------------------
plot(posterior_sample)

#######################################################
#################### DIAGNOSTICS ######################
#######################################################

# diagMCMC(posterior_sample,saveName = "diagMCMCeg",
# saveType = "jpg")

#######################################################
########### POSTERIOR PREDICTIVE DISTRIBUTION #########
#######################################################

theta_sim = as.matrix(posterior_sample)
x_sim = rgamma(nrow(theta_sim), theta_sim[,'shape'], theta_sim[,'rate'])
quantile(x_sim, c(0.025, 0.975))
hist(x_sim, freq = FALSE, xlab = "Ratio of raw speed to posted limit",
     main = "Posterior preditive distribution")
lines(density(x_sim))
abline(v = quantile(x_sim, c(0.025, 0.975)), col = "orange")
```

